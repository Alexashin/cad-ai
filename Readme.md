# CAD-AI

CAD-AI — демонстрационный Python-проект, интегрирующий локальную Large Language Model (LLM) с САПР **КОМПАС-3D**.
Приложение преобразует текстовое описание детали на естественном языке в последовательность команд моделирования и автоматически строит 3D-модель в КОМПАС-3D.

Основной рабочий процесс выглядит следующим образом:

1. Пользователь вводит текстовый запрос, описывающий деталь
   (например: «пластина 120×80, толщина 8 мм, 4 отверстия Ø10 с отступом 15»).
2. Запрос передаётся в локальную LLM, настроенную на генерацию строго структурированного JSON.
3. LLM возвращает JSON-объект, описывающий последовательность операций моделирования.
4. JSON интерпретируется модулем построения.
5. Модуль через COM-API подключается к запущенному КОМПАС-3D и выполняет команды, создавая 3D-модель.

Проект содержит простой графический интерфейс на `tkinter`, позволяющий:

* вводить текстовые запросы,
* генерировать и просматривать JSON,
* строить модель в КОМПАС-3D,
* использовать заранее подготовленные параметрические шаблоны.

---

## Основной функционал

* **Преобразование текста в 3D-модель**
  Использование локальной LLM (формат GGUF, `llama-cpp-python`) для анализа пользовательского запроса.

* **JSON-ориентированный DSL**
  Применяется простой предметно-ориентированный язык (DSL) в формате JSON для описания операций моделирования:
  эскизы, выдавливания, вырезы, рабочие плоскости.

* **Интеграция с КОМПАС-3D**
  Взаимодействие с КОМПАС-3D осуществляется через COM-интерфейсы API5 и API7 с использованием `pywin32`.

* **Параметрическое и признаковое моделирование**
  Модели создаются как последовательность признаков:
  эскизы на базовых плоскостях, 2D-примитивы (линии, окружности), операции выдавливания и выреза.

* **Графический интерфейс пользователя**
  GUI на `tkinter` позволяет управлять процессом, просматривать лог работы и отладочный вывод LLM.

* **Преднастроенные шаблоны**
  В проекте присутствуют устойчивые параметрические шаблоны (куб, пластина с отверстиями, уголок, ступенчатый блок),
  которые используются как демонстрационные примеры и как few-shot примеры для LLM.

---

## Структура проекта

```
.
├── cad_ai/                    # Основной исходный код приложения
│   ├── kompas/                # Работа с КОМПАС-3D
│   │   ├── connection.py      # Подключение по COM, создание документа
│   │   └── builder.py         # Интерпретация JSON и построение модели
│   ├── llm/                   # Работа с LLM
│   │   ├── engine.py          # Обёртка над llama-cpp-python
│   │   ├── prompt.py          # Формирование промпта (few-shot)
│   │   └── validate.py        # Проверка и нормализация JSON
│   ├── templates/             # Параметрические шаблоны моделей
│   │   └── ai_templates.py
│   └── ui/                    # Пользовательский интерфейс
│       └── app.py             # Главное окно tkinter
├── kompas_sdk/                # Вспомогательные файлы API КОМПАС-3D
├── models/                    # Локальные GGUF-модели LLM
├── run_demo.py                # Точка входа в приложение
└── requirements.txt           # Зависимости Python
```

---

## Требования

### Программное обеспечение

* Операционная система **Windows**
* Установленный **КОМПАС-3D** с зарегистрированными COM-серверами

### LLM-модель

* Локальная LLM в формате **GGUF**
* По умолчанию используется модель
  `qwen2.5-1.5b-instruct-q4_k_m.gguf`, размещённая в каталоге `models/`
* Путь к модели может быть изменён в конфигурации проекта

### Зависимости Python

Проект использует:

* `pywin32` — для работы с COM-интерфейсами КОМПАС-3D
* `llama-cpp-python` — для запуска локальной LLM

---

## Запуск проекта

1. **Клонировать репозиторий**

   ```bash
   git clone https://github.com/Alexashin/cad-ai.git
   cd cad-ai
   ```

2. **Запустить КОМПАС-3D**

   Перед запуском приложения КОМПАС-3D должен быть запущен.

3. **Подготовить файлы SDK КОМПАС**

   Убедитесь, что необходимые вспомогательные файлы API
   (`MiscellaneousHelpers.py`, `LDefin2D.py` и др.)
   находятся в каталоге `kompas_sdk/`.

4. **Добавить LLM-модель**

   Скачайте GGUF-модель и поместите её в каталог `models/`.

5. **Установить зависимости**

   ```bash
   pip install -r requirements.txt
   ```

   **Установка `llama-cpp-python`**

   Библиотека для запуска локальной LLM устанавливается отдельно, так как может требовать
   компиляции под конкретную систему (CUDA 12.6 по необходимости):

   ```bash
   pip install llama-cpp-python
   ```

6. **Запустить приложение**

   ```bash
   python run_demo.py
   ```

После запуска откроется графический интерфейс, в котором можно:

* подключиться к КОМПАС-3D,
* ввести текстовый запрос,
* сгенерировать JSON,
* построить модель,
* либо использовать готовые шаблоны.
